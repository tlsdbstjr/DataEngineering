{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë³´ë°°ë“œë¦¼ ëŒë‹¤ ë””í…Œì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from bobaedream_utils import (\n",
    "    clean_date_string,\n",
    "    prepare_for_spark,\n",
    "    save_html,\n",
    ")\n",
    "\n",
    "from common_utils import (\n",
    "    get_db_connection,\n",
    "    save_s3_bucket_by_parquet,\n",
    "    upsert_post_tracking_data,\n",
    "    get_details_to_parse,\n",
    "    update_status_banned,\n",
    "    update_status_failed,\n",
    "    update_status_changed,\n",
    "    update_status_unchanged,\n",
    "    update_changed_stats,\n",
    "    get_my_ip,\n",
    "    analyze_post_with_gpt,\n",
    "    get_proxy_ip,\n",
    "    return_proxy_ip,\n",
    ")\n",
    "\n",
    "# ë©€í‹°ìŠ¤ë ˆë“œë¥¼ ìœ„í•œ ì„¤ì •\n",
    "analysis_executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "linebreak_ptrn = re.compile(r'(\\n){2,}')  # ì¤„ë°”ê¿ˆ ë¬¸ì ë§¤ì¹­\n",
    "\n",
    "def analyze_post(payload):\n",
    "    \"\"\"í¬ë¡¤ë§ëœ ë°ì´í„°ë¥¼ ê°ì„± ë¶„ì„ ìˆ˜í–‰\"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ­ ê°ì„± ë¶„ì„ ì‹œì‘: {payload['url']}\")\n",
    "        analyzed_post = analyze_post_with_gpt(payload)\n",
    "        print(f\"âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ: {payload['url']}\")\n",
    "        return analyzed_post\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "        payload['sentiment'] = None\n",
    "        for comment in payload['comment']:\n",
    "            comment['sentiment'] = None\n",
    "        return payload\n",
    "    \n",
    "def process_batch(futures: List) -> List[Dict]:\n",
    "    \"\"\"ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê°ì„± ë¶„ì„ ì²˜ë¦¬\"\"\"\n",
    "    results = []\n",
    "       \n",
    "    # ì™„ë£Œëœ ì‘ì—…ë“¤ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch item: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_post_meta(post, post_meta):\n",
    "    # í¬ìŠ¤íŒ… ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "    title_elem = post_meta.find('dt')\n",
    "    if title_elem is None:\n",
    "        print(\"[ERROR] ì œëª© íŒŒì‹± ì‹¤íŒ¨.\")    \n",
    "    post['title'] = title_elem['title']    \n",
    "    count_group = post_meta.find('span', class_='countGroup')\n",
    "    count_group_em = count_group.find_all('em')\n",
    "    try:\n",
    "        view = count_group_em[0].text\n",
    "        view = int(view.replace(',', ''))  # ì‰¼í‘œ ì œê±°\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] ì¡°íšŒìˆ˜ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        view = -999\n",
    "    try:\n",
    "        like = count_group_em[2].text\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] ì¢‹ì•„ìš” íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        like = -999\n",
    "    date_raw = count_group.text\n",
    "    date_str = date_raw.split('|')[-1].strip()\n",
    "    try:\n",
    "        posting_datetime = clean_date_string(date_str)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        posting_datetime = datetime.strptime('0000-01-01', '%Y-%m-%d')\n",
    "    post['view'] = view\n",
    "    post['like'] = like # like ë“±ì€ ì—¬ê¸°ì„œ ì²˜ë¦¬í•´ì•¼ í•¨.        \n",
    "    post['dislike'] = None\n",
    "    post['created_at'] = posting_datetime\n",
    "\n",
    "def parse_detail(total_rows:int = 1):\n",
    "    # -> Union[List[Dict] | int | None]\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ ê²°ê³¼ì˜ ê° ê²Œì‹œë¬¼ì— ëŒ€í•´ ìƒì„¸ ì •ë³´ë¥¼ íŒŒì‹±í•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        search_results: ê²€ìƒ‰ëœ ê²Œì‹œë¬¼ ëª©ë¡ ([{title, link, ...}, ...])\n",
    "    \n",
    "    Returns:\n",
    "        ìƒì„¸ ì •ë³´ê°€ ì¶”ê°€ëœ ê²Œì‹œë¬¼ ëª©ë¡\n",
    "    \"\"\"\n",
    "    lambda_time = time.time()\n",
    "    headers = {\n",
    "        # 'User-Agent': UserAgent,\n",
    "        'Host': 'www.bobaedream.co.kr',\n",
    "        'Origin': 'https://www.bobaedream.co.kr',\n",
    "        'Referer': 'https://www.bobaedream.co.kr/search',\n",
    "        \"Accept-Language\":\"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Encoding\":\"gzip, deflate, br, zstd\",\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8'\n",
    "        }\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    if conn is None:\n",
    "        print(\"[ERROR] DB ì—°ê²° ì‹¤íŒ¨\")\n",
    "        return 500, []\n",
    "    \n",
    "    payloads = []\n",
    "    current_batch = []\n",
    "    BATCH_SIZE = 50\n",
    "    PROXY_RETRY_CNT = 5 # ë°´ ë‹¹í•  ì‹œ í”„ë¡ì‹œë¡œ ì¬ì ‘ì† ì‹œë„ íšŸìˆ˜\n",
    "    \n",
    "    status_code = 200\n",
    "    table_name = 'probe_bobae'\n",
    "    while True:\n",
    "        if time.time() - lambda_time > 810:\n",
    "            print(\"[INFO] ëŒë‹¤ í•¨ìˆ˜ ì‹œê°„ ì´ˆê³¼\")\n",
    "            status_code = 408\n",
    "            break\n",
    "        \n",
    "        # DBì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ê²Œì‹œë¬¼ ëª©ë¡\n",
    "        post = get_details_to_parse(conn, table_name, total_rows=total_rows)\n",
    "        if post is None:\n",
    "            print(\"[ERROR] DB ì¡°íšŒ ì‹¤íŒ¨\")\n",
    "            status_code = 500\n",
    "            break\n",
    "        \n",
    "        if post == []:\n",
    "            print(\"[INFO] íŒŒì‹±í•  ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            status_code = 204\n",
    "            break\n",
    "    \n",
    "        try:\n",
    "            post_url = post['url']\n",
    "            print(f\"ìš”ì²­ í”Œë«í¼: ë³´ë°°ë“œë¦¼ / '{post_url}' ê²€ìƒ‰ ì¤‘...\")\n",
    "            isBanned = False    # ë°´ ë‹¹í•˜ë©´ True\n",
    "            try:\n",
    "                response = requests.get(\n",
    "                        post_url,\n",
    "                        headers=headers,\n",
    "                        timeout=10,\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] ìš”ì²­ ì‹¤íŒ¨: {e}\")\n",
    "                print(f\"ì•„ë§ˆ IP ì°¨ë‹¨ë¨! {response.status_code}, í”„ë¡ì‹œ ì ‘ê·¼ ì‹œë„\")    \n",
    "                # í”„ë¡ì‹œ ì ‘ê·¼ ì‹œë„\n",
    "                isBanned = True\n",
    "                \n",
    "            proxy_try_cnt = 0\n",
    "            while isBanned and proxy_try_cnt > PROXY_RETRY_CNT:\n",
    "                proxy = get_proxy_ip(\"bobaedream\")\n",
    "                if proxy is None:\n",
    "                    # isBanned True\n",
    "                    break\n",
    "                try:\n",
    "                    proxy_try_cnt += 1\n",
    "                    response = requests.get(\n",
    "                            post_url,\n",
    "                            headers=headers,\n",
    "                            timeout=10,\n",
    "                            proxies=proxy\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] í”„ë¡ì‹œ ìš”ì²­ ì‹¤íŒ¨: {e}\")\n",
    "                else:\n",
    "                    isBanned = False\n",
    "                finally:\n",
    "                    return_proxy_ip(proxy[\"http\"], \"bobaedream\", isBanned, isTimeout=False)\n",
    "            \n",
    "            if isBanned:\n",
    "                update_status_banned(conn, table_name, post['url'])\n",
    "                print(f\"[ERROR] í˜ì´ì§€ ì ‘ê·¼ (í”„ë¡ì‹œ ì‚¬ìš©) ì‹¤íŒ¨\")\n",
    "                continue\n",
    "\n",
    "            response.encoding = 'utf-8'\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"[ERROR] í™•ì¸ í•„ìš”! status code: {response.status_code}\")\n",
    "                if response.status_code == 403:\n",
    "                    print(f\"IP ì°¨ë‹¨ë¨! {response.status_code}\")\n",
    "                    update_status_banned(conn, table_name, post['url'])\n",
    "                status_code = response.status_code\n",
    "                break\n",
    "\n",
    "            # ìƒì„¸ í˜ì´ì§€ ìš”ì²­\n",
    "            time.sleep(1 + random.random())\n",
    "                    \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # ëŒ“ê¸€ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ì²˜ë¦¬\n",
    "            has_comment = True\n",
    "            try:\n",
    "                comment_list = soup.find('div', id='cmt_list').find('ul', class_='basiclist').find_all('li')\n",
    "                comment_count = len(comment_list)\n",
    "            except Exception as e:\n",
    "                print(f\"[INFO] ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤. {e} / post_url: {post_url}\")\n",
    "                has_comment = False\n",
    "                comment_count = 0\n",
    "            finally:\n",
    "                post['comment_count'] = comment_count\n",
    "\n",
    "            # ë³¸ë¬¸ ë‚´ìš© íŒŒì‹±\n",
    "            content_element = soup.find('div', class_='bodyCont')\n",
    "            try:\n",
    "                cleaned_content = content_element.text.strip().replace('\\xa0', ' ')\n",
    "                cleaned_content = linebreak_ptrn.sub('\\n', cleaned_content)\n",
    "                post['content'] = cleaned_content\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] ë³¸ë¬¸ ë‚´ìš© íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "                continue\n",
    "            try:\n",
    "                post_meta = soup.find('div', class_='writerProfile').find('dl')\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] í¬ìŠ¤íŒ… ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "                post_meta = None\n",
    "                continue\n",
    "            if post_meta is None:\n",
    "                print(\"[ERROR] í¬ìŠ¤íŒ… ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨.\")\n",
    "            else:\n",
    "                # í¬ìŠ¤íŒ… ë©”íƒ€ë°ì´í„° íŒŒì‹±\n",
    "                parse_post_meta(post, post_meta)\n",
    "            \n",
    "            # ëŒ“ê¸€ ì²˜ë¦¬\n",
    "            comment_data = []\n",
    "            if has_comment:\n",
    "                for comment in comment_list: # \n",
    "                    if \"ì‚­ì œëœ ëŒ“ê¸€ì…ë‹ˆë‹¤\" in comment.text:\n",
    "                        comment_data.append({\n",
    "                            'created_at': None,\n",
    "                            'content': None,\n",
    "                            'like': None,\n",
    "                            'dislike': None\n",
    "                        })\n",
    "                        continue\n",
    "                    try:\n",
    "                        comment_meta = comment.find('dl').find('dt').find_all('span')\n",
    "                    except Exception as e:\n",
    "                        print(f\"[ERROR] ëŒ“ê¸€ ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "                        continue\n",
    "                    \n",
    "                    if comment_meta is None:\n",
    "                        print(\"[ERROR] ëŒ“ê¸€ ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨.\")\n",
    "                        continue\n",
    "                    try:\n",
    "                        # comment_name = comment_meta[1].text\n",
    "                        comment_date = datetime.strptime(comment_meta[3].text, '%y.%m.%d %H:%M')\n",
    "                        comment_content = comment.find('dd').text.strip()\n",
    "                        comment_like_dislike = comment.find('div', class_='updownbox').find_all('dd')\n",
    "                        comment_like = comment_like_dislike[0].text.replace('ì¶”ì²œ ', '') \n",
    "                        comment_dislike = comment_like_dislike[1].text.replace('ë°˜ëŒ€ ', '')\n",
    "                        comment_data.append({\n",
    "                            'created_at': comment_date,\n",
    "                            'content': comment_content,\n",
    "                            'like': comment_like,\n",
    "                            'dislike': comment_dislike\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"[ERROR] ëŒ“ê¸€ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "                        continue\n",
    "            payload = {\n",
    "                'checked_at': post['checked_at'],\n",
    "                'platform': 'bobaedream',\n",
    "                'title': post['title'],\n",
    "                'post_id': post['post_id'],\n",
    "                'url': post['url'],\n",
    "                'content': post['content'],\n",
    "                'view': post['view'],\n",
    "                'created_at': post['created_at'],\n",
    "                'like': post['like'],\n",
    "                'dislike': post['dislike'],\n",
    "                'comment_count': post['comment_count'],\n",
    "                'keywords': post['keywords'],\n",
    "                'comment': comment_data,\n",
    "                'status': 'UNCHANGED',\n",
    "            }       \n",
    "            \n",
    "            post['status'] = 'UNCHANGED'\n",
    "            \n",
    "            # ëª¨ë“  í¬ìŠ¤íŠ¸ì— ëŒ€í•´ ë¶„ì„ ì‘ì—… ì œì¶œ\n",
    "            future = analysis_executor.submit(analyze_post, payload)\n",
    "            current_batch.append(future)\n",
    "            # ì™„ë£Œëœ ì‘ì—…ë“¤ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘\n",
    "            if len(current_batch) >= BATCH_SIZE:\n",
    "                print(f\"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (í¬ê¸°: {len(current_batch)})\")\n",
    "                batch_results = process_batch(current_batch)\n",
    "                payloads.extend(batch_results)\n",
    "                current_batch = []\n",
    "\n",
    "            is_success = update_changed_stats(conn, table_name, post['url'], post['comment_count'], post['view'], post['created_at'])            \n",
    "            if is_success:\n",
    "                print(f\"[INFO] {post['url']} ì—…ë°ì´íŠ¸ ì„±ê³µ\")\n",
    "            else:\n",
    "                print(f\"[INFO] {post['url']} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            post['status'] = 'FAILED'\n",
    "            payloads.append({\n",
    "                'status': 'FAILED',\n",
    "            })\n",
    "            update_status_failed(conn, table_name, post['url'])\n",
    "            print(f\"[ERROR] {post['url']} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ / ì´ìœ : {e}\")    \n",
    "\n",
    "    # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬\n",
    "    if current_batch:\n",
    "        print(f\"ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬ (í¬ê¸°: {len(current_batch)})\")\n",
    "        batch_results = process_batch(current_batch)\n",
    "        payloads.extend(batch_results)\n",
    "    payloads = [payload for payload in payloads if payload['status'] == 'UNCHANGED']\n",
    "    if payloads:\n",
    "        print(f\"[INFO] ë³€ê²½ëœ ë°ì´í„°ê°€ {len(payloads)} ê±´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        status_code = 201\n",
    "    return status_code, payloads\n",
    "        \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # python -m bobaedream.bobaedream_exec ë¡œ ì‹¤í–‰\n",
    "    total_rows = event.get(\"total_rows\", 1)\n",
    "    id = event.get(\"id\")\n",
    "\n",
    "    get_my_ip()\n",
    "    table_name = 'probe_bobae'\n",
    "    status_code, details_data = parse_detail(total_rows)\n",
    "    if details_data == 500:\n",
    "        return {\n",
    "            \"status_code\": 500,\n",
    "            \"body\": \"[ERROR] DETAIL / DB ì—°ê²° ì‹¤íŒ¨\"\n",
    "        }\n",
    "    elif details_data == []:\n",
    "        return {\n",
    "            \"status_code\": 201,\n",
    "            \"body\": \"[INFO] DETAIL / S3ì— ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        checked_at_dt = details_data[0]['checked_at']\n",
    "        res = save_s3_bucket_by_parquet(\n",
    "            checked_at_dt=checked_at_dt,\n",
    "            platform=\"bobaedream\", \n",
    "            data=details_data,\n",
    "            id=id\n",
    "        )\n",
    "        if res == True:\n",
    "            return {\n",
    "                \"status_code\": 200,\n",
    "                \"body\": f\"[INFO] S3 ì €ì¥ ì™„ë£Œ: {len(details_data)} ê±´\"\n",
    "            }\n",
    "        else:\n",
    "            raise\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] S3 ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        conn = get_db_connection()\n",
    "        if details_data:\n",
    "            for detail in details_data:\n",
    "                update_status_changed(conn, table_name, detail[\"url\"])\n",
    "        return {\n",
    "            \"status_code\": 500,\n",
    "            \"body\": \"[ERROR] S3 ì €ì¥ ì‹¤íŒ¨\"\n",
    "        }\n",
    "    finally:\n",
    "        if status_code == 403:\n",
    "            return {\n",
    "                \"status_code\": 403,\n",
    "                \"body\": f\"[WARNING] DETAIL / IP ì°¨ë‹¨ë¨ / í¬ë¡¤ë§ ë°ì´í„°: {len(details_data)} ê±´\"\n",
    "            }\n",
    "        elif status_code == 408:\n",
    "            return {\n",
    "                \"status_code\": 408,\n",
    "                \"body\": f\"[WARNING] DETAIL / ëŒë‹¤ í•¨ìˆ˜ ì‹œê°„ ì´ˆê³¼ / í¬ë¡¤ë§ ë°ì´í„°: {len(details_data)} ê±´\"\n",
    "            }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë³´ë°°ë“œë¦¼ ëŒë‹¤ ì„œì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from bobaedream_utils import (\n",
    "    post_id_salt\n",
    ")\n",
    "\n",
    "from common_utils import (\n",
    "    get_db_connection,\n",
    "    upsert_post_tracking_data,\n",
    "    get_my_ip,\n",
    "    get_proxy_ip,\n",
    "    return_proxy_ip,\n",
    ")\n",
    "linebreak_ptrn = re.compile(r'(\\n){2,}')  # ì¤„ë°”ê¿ˆ ë¬¸ì ë§¤ì¹­\n",
    "\n",
    "def extract_bobaedream(start_date, page_num, keyword) -> Optional[str]:\n",
    "    print(f\"ì‹œì‘ ë‚ ì§œ ë° ì‹œê°„: {start_date.strftime('%y.%m.%d')}\")\n",
    "    form_data = {\n",
    "        \"keyword\": keyword,\n",
    "        \"colle\": \"community\",\n",
    "        \"searchField\": \"ALL\",\n",
    "        \"page\": page_num,\n",
    "        \"sort\": \"DATE\",\n",
    "        'startDate': start_date.strftime('%y.%m.%d'),\n",
    "    }\n",
    "    # data = urlencode(form_data)\n",
    "    data = form_data\n",
    "    # ì´í›„ ë§‰íˆë©´ ìˆ˜ì • í•„ìš”í•  ìˆ˜ë„.\n",
    "    # UA, cookies, proxies, headers ë“±ì„ ì¶”ê°€í•´ì•¼ í•  ìˆ˜ë„ ìˆìŒ.\n",
    "    # ì¿ í‚¤ëŠ”  \n",
    "    # ì¿ í‚¤ëŠ” í•œ ë²ˆ seleniumìœ¼ë¡œ ë¡œê·¸ì¸í•´ì„œ ë°›ì•„ì˜¤ë©´ ê·¸ê±¸ë¡œ ì“°ë©´ ë¨.\n",
    "    # ë§‰íˆë©´ ëª¨ë°”ì¼ë¡œë„ ê³ ë ¤ (touch ë“± js ì½”ë“œì— ì—†ì–´ì„œ ëª¨ë°”ì¼ë¡œ í•˜ë©´ ë¬´ì¡°ê±´ ê°€ëŠ¥í•  ë“¯).\n",
    "    \n",
    "    # UserAgent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "    headers = {\n",
    "        'Host': 'www.bobaedream.co.kr',\n",
    "        'Origin': 'https://www.bobaedream.co.kr',\n",
    "        'Referer': 'https://www.bobaedream.co.kr/search',\n",
    "        \"Accept-Language\":\"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Encoding\":\"gzip, deflate, br, zstd\",\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8'\n",
    "        }\n",
    "    \n",
    "    print(f\"ìš”ì²­ í”Œë«í¼: ë³´ë°°ë“œë¦¼ / í˜ì´ì§€ {page_num}ì—ì„œ '{keyword}' ê²€ìƒ‰ ì¤‘...\")\n",
    "    time.sleep(1)\n",
    "    response = requests.post(\n",
    "            'https://www.bobaedream.co.kr/search', \n",
    "            data=data,\n",
    "            headers=headers\n",
    "        )\n",
    "    # cookies = response.cookies\n",
    "    # response_headers = response.headers\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    \n",
    "    print(f\"í™•ì¸ í•„ìš”! status code: {response.status_code}\")\n",
    "    while response.status_code == 403:\n",
    "        print(f\"[INFO] SEARCH / ë³´ë°°ë“œë¦¼ IP ì°¨ë‹¨ë¨! {response.status_code} - í”„ë¡ì‹œ ì‹œë„\")\n",
    "        proxy = get_proxy_ip(\"bobaedream\")\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                'https://www.bobaedream.co.kr/search', \n",
    "                data=data,\n",
    "                headers=headers,\n",
    "                proxies=proxy\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[INFO] í”„ë¡ì‹œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return_proxy_ip(proxy[\"http\"], \"bobaedream\", isBanned=True, isTimeout=True)\n",
    "        else:\n",
    "            return_proxy_ip(proxy[\"http\"], \"bobaedream\", isBanned=response.status_code == 403, isTimeout=False)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"[WARNING] ê¸°íƒ€ ì˜¤ë¥˜ / {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "def parse_search(\n",
    "        html, \n",
    "        start_dt: datetime, \n",
    "        end_dt: datetime, \n",
    "        checked_at: datetime,\n",
    "        keyword: str\n",
    "    ) -> Optional[bool]:\n",
    "    soup = BeautifulSoup(html, 'html.parser', from_encoding='utf-8')\n",
    "    \n",
    "    community_results = soup.find_all('div', class_='search_Community')\n",
    "    # search_data = []\n",
    "    if not community_results:\n",
    "        print('[ERROR] ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜, ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')\n",
    "        return 404\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    if conn is None:\n",
    "        print(\"[ERROR] DB ì—°ê²° ì‹¤íŒ¨\")\n",
    "        return 500\n",
    "    \n",
    "    table_name = 'probe_bobae'\n",
    "    for community_result in community_results:\n",
    "        # ul íƒœê·¸ë“¤ ì°¾ê¸°\n",
    "        lis = community_result.find_all('li')\n",
    "        if not lis:\n",
    "            print('[INFO] ê²€ìƒ‰ ê²°ê³¼ê°€ ë”ì´ìƒ ì—†ìŠµë‹ˆë‹¤.')\n",
    "            # save_html('htmls/search', html)\n",
    "            return True\n",
    "\n",
    "        for li in lis:\n",
    "            payload = {\n",
    "                'platform': 'bobaedream',\n",
    "                'checked_at': checked_at,\n",
    "            }\n",
    "            # ê° li ì•ˆì—ì„œ dt > a ì°¾ê¸°\n",
    "            try:\n",
    "                a_tag = li.find('dt').find('a')\n",
    "                # íƒ€ì´í‹€ê³¼ url íŒŒì‹±\n",
    "                title = a_tag.text.strip()\n",
    "                url = a_tag['href']\n",
    "            except Exception as e:\n",
    "                print(f\"dt í˜¹ì€ a íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. : {e}\")\n",
    "                continue\n",
    "            else:\n",
    "                payload['title'] = title\n",
    "                payload['url'] = f\"https://www.bobaedream.co.kr{url}\"                \n",
    "\n",
    "            # ê° li ì•ˆì—ì„œ dd > span ì°¾ê¸°\n",
    "            try:    \n",
    "                spans = li.find('dd', class_='path').find_all('span')\n",
    "                # span íƒœê·¸ íŒŒì‹±\n",
    "                if spans[0].text == 'news':\n",
    "                    print(f\"ë‰´ìŠ¤: {title}, url: {payload['url']}\")\n",
    "                    # continue\n",
    "                payload['category'] = spans[0].text\n",
    "                payload['writer'] = spans[1].text\n",
    "                payload['post_id'] = url.split('No=')[1]\n",
    "                payload['post_id'] = post_id_salt(payload['post_id'], payload['category'])\n",
    "                created_at = spans[2].text\n",
    "            except Exception as e:\n",
    "                print(f\"span íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. : {e}\")\n",
    "                continue\n",
    "            else:\n",
    "                created_at_dt = datetime.strptime(created_at, '%y. %m. %d')\n",
    "                payload['created_at'] = created_at_dt\n",
    "                    # 2000ë…„ëŒ€ë¡œ ê°€ì •\n",
    "                if created_at_dt.year < 100:\n",
    "                    created_at_dt = created_at_dt.replace(year=created_at_dt.year + 2000)\n",
    "\n",
    "                if created_at_dt > end_dt:\n",
    "                    print(f'[INFO] ê¸°ê°„ì´ ë” ë’¤ì´ê¸°ì— ë„˜ì–´ê°‘ë‹ˆë‹¤. {end_dt} / ê²Œì‹œê¸€ ë‚ ì§œ: {created_at_dt}')\n",
    "                    continue\n",
    "                \n",
    "                if created_at_dt < start_dt:\n",
    "                    print(f'[INFO] ê¸°ê°„ì´ ë” ì•ì´ê¸°ì— ì¢…ë£Œí•©ë‹ˆë‹¤. {start_dt} / ê²Œì‹œê¸€ ë‚ ì§œ: {created_at_dt}')\n",
    "                    return True\n",
    "\n",
    "                if payload['category'] == 'ë‚´ì°¨ì‚¬ì§„':\n",
    "                    print(f'[WARNING] ë‚´ì°¨ì‚¬ì§„ì´ì–´ì„œ ìŠ¤í‚µí•©ë‹ˆë‹¤. {title}')\n",
    "                    continue\n",
    "            \n",
    "            payload['view'] = -999 # ë°˜ë“œì‹œ ì—…ë°ì´íŠ¸ë˜ê²Œë” ì„¤ì •í•¨. # ë³´ë°°ë“œë¦¼ íŠ¹ì´ ì¼€ì´ìŠ¤ì„. (intì—¬ì•¼ í•¨!)\n",
    "            payload['comment_count'] = -999 # ë°˜ë“œì‹œ ì—…ë°ì´íŠ¸ë˜ê²Œë” ì„¤ì •í•¨. # ë³´ë°°ë“œë¦¼ íŠ¹ì´ ì¼€ì´ìŠ¤ì„. (intì—¬ì•¼ í•¨!)\n",
    "            payload['status'] = 'CHANGED'  # ë°˜ë“œì‹œ ì—…ë°ì´íŠ¸ë˜ê²Œë” ì„¤ì •í•¨.\n",
    "            payload['keyword'] = keyword\n",
    "            # DBì— ë³€ê²½ì‚¬í•­ ì €ì¥\n",
    "            # comment_count, viewë¥¼ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©´ ë°”ë¡œ ì—…ë°ì´íŠ¸.\n",
    "            upsert_post_tracking_data(\n",
    "                    conn=conn,\n",
    "                    table_name=table_name,\n",
    "                    payload=payload\n",
    "                )\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    keyword, checked_at í•„ìˆ˜.\n",
    "    start_date, \n",
    "    end_dateëŠ” ì„ íƒ.\n",
    "    \"\"\"\n",
    "    #TODO: ë¬´ì¡°ê±´ ë°”ê¿”ì•¼ í•¨! (end_date ì´ìƒ ë„˜ì–´ê°€ë©´ ì•ˆë˜ê²Œë”.)\n",
    "    # ì´ê²Œ í¬ë¡¤ë§í•œ ì‹œê°„.\n",
    "    checked_at_str = event.get('checked_at')\n",
    "    # ISO 8601 í˜•ì‹ â†’ UTC ê¸°ì¤€\n",
    "    if checked_at_str:\n",
    "        event_time = datetime.fromisoformat(checked_at_str)\n",
    "    else:\n",
    "        event_time = datetime.now(timezone.utc).replace(tzinfo=None)  # ëª…ì‹œì ìœ¼ë¡œ UTC ì‹œê°„ì„ ê°€ì ¸ì˜¨ í›„ timezone ì •ë³´ ì œê±°\n",
    "    # UTC ì‹œê°„ì— 9ì‹œê°„ì„ ë”í•´ KST ì‹œê°„ìœ¼ë¡œ ë³€í™˜\n",
    "    checked_at = event_time + timedelta(hours=9)  # UTC+9 (KST)\n",
    "    # KST ì‹œê°„ ì¶œë ¥ (í˜•ì‹: â€˜YYYY-MM-DD HH:MM:SSâ€™)\n",
    "    print(\"í•œêµ­ ì‹œê°„:\", checked_at.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    # ê²Œì‹œê¸€ ì‹œì‘ ë‚ ì§œ\n",
    "    start_date = event.get('start_date')\n",
    "    if start_date is None:\n",
    "        start_dt = checked_at - timedelta(days=14)\n",
    "    else:\n",
    "        start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        # start_dt = start_dt.replace(tzinfo=timezone.utc)  # UTCë¡œ ë³€í™˜\n",
    "    \n",
    "    # ê²Œì‹œê¸€ ì¢…ë£Œ ë‚ ì§œ\n",
    "    end_date = event.get('end_date')\n",
    "    if end_date is None:\n",
    "        end_dt = checked_at + timedelta(days=0)\n",
    "    else:\n",
    "        end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        # end_dt = end_dt.replace(tzinfo=timezone.utc)\n",
    "    \n",
    "    get_my_ip()\n",
    "    \n",
    "    # ê²€ìƒ‰í•  í‚¤ì›Œë“œ\n",
    "    keyword = event.get('keyword')\n",
    "    for i in range(1, 1000):\n",
    "        html = extract_bobaedream(start_date, page_num=i, keyword=keyword)\n",
    "        # save_html('htmls/search', html)\n",
    "        if html is None:\n",
    "            return {\n",
    "                \"status_code\": 403,\n",
    "                \"body\": \"[WARNING] SEARCH / ë³´ë°°ë“œë¦¼(platformìœ¼ë¡œ ëŒ€ì²´) IP ì°¨ë‹¨ë¨!\"\n",
    "            }\n",
    "        result = parse_search(html, start_dt=start_dt, end_dt=end_dt, checked_at=checked_at, keyword=keyword)   \n",
    "        if result == 404:\n",
    "            print(f\"[INFO] ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. {keyword}\")\n",
    "        \n",
    "        if result == 500:\n",
    "            print(f\"[ERROR] DB ì—°ê²° ì‹¤íŒ¨: {keyword}\")\n",
    "            return {\n",
    "                \"status_code\": 500,\n",
    "                \"body\": \"[ERROR] SEARCH / DB ì—°ê²° ì‹¤íŒ¨\"\n",
    "            }\n",
    "            \n",
    "        if result == True:\n",
    "            print(f\"[INFO] ë³´ë°°ë“œë¦¼ ê²€ìƒ‰ ì¢…ë£Œ: {keyword}\")\n",
    "            return {\n",
    "                \"status_code\": 200,\n",
    "                \"body\":  \"[INFO] SEARCH / DB ì—…ë°ì´íŠ¸ ì„±ê³µ\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 'test', 'aaa': 'bbb'}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = {\"this\": \"test\", \"aaa\": \"bbb\"}\n",
    "print (a)\n",
    "print (len (a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
