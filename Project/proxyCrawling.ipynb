{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/anaconda3/lib/python3.12/site-packages (2.9.10)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests\n",
    "! pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import psycopg2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://free-proxy-list.net/#\"\n",
    "response = requests.get(url)\n",
    "assert response.status_code == 200, f\"Error! - status code:{response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 0.0.0.0:80\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}):(\\d+)\"\n",
    "#print(response.content)\n",
    "\n",
    "matches = re.findall(pattern, str(response.content))\n",
    "result = [f\"{ip}:{port}\" for ip, port in matches]\n",
    "for i, r in enumerate(result):\n",
    "    if r == \"0.0.0.0:80\":\n",
    "        print(i,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = \"proxy_ip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = \"proxy_ip\"\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"postgres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"5nlyhdrds\",\n",
    "        host=\"onlyhd-rds.chgj4wuiuimb.ap-northeast-2.rds.amazonaws.com\",\n",
    "        port=5432\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {TABLE_NAME}(\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    data VACAHR(255)\n",
    "                );\n",
    "                \"\"\")\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(\"error! - \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"INSERT INTO {TABLE_NAME} (data) VALUES (%s)\", (result,))\n",
    "    conn.commit()\n",
    "    print(\"데이터가 성공적으로 삽입되었습니다.\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"데이터베이스 오류: {e}\")\n",
    "    conn.rollback()\n",
    "\n",
    "finally:\n",
    "    if cur:\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO proxy_ip (ip)\n",
      "VALUES\n",
      "('137.184.100.135:80'),\n",
      "('63.143.57.119:80'),\n",
      "('3.99.167.1:3128'),\n",
      "('104.225.220.233:80'),\n",
      "('18.223.25.15:80'),\n",
      "('50.223.246.237:80'),\n",
      "('50.174.7.159:80'),\n",
      "('41.207.187.178:80'),\n",
      "('32.223.6.94:80'),\n",
      "('82.119.96.254:80'),\n",
      "('67.43.236.19:30903'),\n",
      "('13.37.89.201:80'),\n",
      "('13.36.113.81:3128'),\n",
      "('44.218.183.55:80'),\n",
      "('50.207.199.80:80'),\n",
      "('50.207.199.83:80'),\n",
      "('50.174.7.153:80'),\n",
      "('50.202.75.26:80'),\n",
      "('50.169.37.50:80'),\n",
      "('165.232.129.150:80'),\n",
      "('50.239.72.18:80'),\n",
      "('50.175.212.66:80'),\n",
      "('50.217.226.47:80'),\n",
      "('50.239.72.16:80'),\n",
      "('50.239.72.19:80'),\n",
      "('50.217.226.40:80'),\n",
      "('50.221.74.130:80'),\n",
      "('190.58.248.86:80'),\n",
      "('50.175.212.74:80'),\n",
      "('50.122.86.118:80'),\n",
      "('37.187.25.85:80'),\n",
      "('103.152.112.120:80'),\n",
      "('184.169.154.119:80'),\n",
      "('13.56.192.187:80'),\n",
      "('43.163.87.93:8080'),\n",
      "('43.224.248.29:8085'),\n",
      "('34.87.84.105:80'),\n",
      "('23.247.136.254:80'),\n",
      "('103.152.112.157:80'),\n",
      "('3.71.239.218:3128'),\n",
      "('43.202.154.212:80'),\n",
      "('35.76.62.196:80'),\n",
      "('35.79.120.242:3128'),\n",
      "('46.51.249.135:3128'),\n",
      "('43.200.77.128:3128'),\n",
      "('43.201.121.81:80'),\n",
      "('52.196.1.182:80'),\n",
      "('3.12.144.146:3128'),\n",
      "('18.228.198.164:80'),\n",
      "('52.67.10.183:80'),\n",
      "('103.54.218.77:8080'),\n",
      "('63.143.57.116:80'),\n",
      "('103.152.112.159:80'),\n",
      "('46.47.197.210:3128'),\n",
      "('204.236.176.61:3128'),\n",
      "('3.130.65.162:3128'),\n",
      "('13.48.109.48:3128'),\n",
      "('13.246.209.48:1080'),\n",
      "('99.80.11.54:3128'),\n",
      "('51.20.50.149:3128'),\n",
      "('13.246.184.110:3128'),\n",
      "('52.65.193.254:3128'),\n",
      "('13.213.114.238:3128'),\n",
      "('52.16.232.164:3128'),\n",
      "('3.97.167.115:3128'),\n",
      "('51.16.179.113:1080'),\n",
      "('103.149.201.160:30008'),\n",
      "('63.32.1.88:3128'),\n",
      "('54.179.44.51:3128'),\n",
      "('16.16.239.39:3128'),\n",
      "('13.55.210.141:3128'),\n",
      "('54.228.164.102:3128'),\n",
      "('123.30.154.171:7777'),\n",
      "('31.47.58.37:80'),\n",
      "('3.141.217.225:80'),\n",
      "('203.115.101.61:82'),\n",
      "('51.68.175.56:1080'),\n",
      "('3.90.100.12:80'),\n",
      "('50.169.222.243:80'),\n",
      "('50.169.222.241:80'),\n",
      "('142.44.210.174:80'),\n",
      "('63.35.64.177:3128'),\n",
      "('91.149.224.226:1080'),\n",
      "('204.236.137.68:80'),\n",
      "('52.73.224.54:3128'),\n",
      "('66.29.154.105:3128'),\n",
      "('181.41.194.186:80'),\n",
      "('222.252.194.204:8080'),\n",
      "('50.217.226.41:80'),\n",
      "('162.223.90.130:80'),\n",
      "('50.207.199.86:80'),\n",
      "('144.126.216.57:80'),\n",
      "('133.18.234.13:80'),\n",
      "('0.0.0.0:80'),\n",
      "('211.128.96.206:80'),\n",
      "('68.185.57.66:80'),\n",
      "('50.231.104.58:80'),\n",
      "('50.174.7.156:80'),\n",
      "('50.207.199.81:80'),\n",
      "('127.0.0.7:80'),\n",
      "('102.69.32.1:8080'),\n",
      "('91.220.109.197:15653'),\n",
      "('109.191.63.90:8081'),\n",
      "('1.4.163.42:8080'),\n",
      "('192.121.102.13:8118'),\n",
      "('156.228.81.226:3128'),\n",
      "('156.228.87.250:3128'),\n",
      "('104.207.61.33:3128'),\n",
      "('156.228.94.188:3128'),\n",
      "('104.207.53.113:3128'),\n",
      "('156.228.83.229:3128'),\n",
      "('217.160.224.54:8118'),\n",
      "('102.132.55.99:8080'),\n",
      "('54.199.11.46:9001'),\n",
      "('201.159.99.37:8081'),\n",
      "('103.247.21.44:1111'),\n",
      "('103.231.239.166:58080'),\n",
      "('154.159.247.119:8080'),\n",
      "('38.41.4.166:999'),\n",
      "('200.39.139.65:999'),\n",
      "('179.57.172.24:999'),\n",
      "('156.228.125.13:3128'),\n",
      "('104.207.54.71:3128'),\n",
      "('104.207.54.213:3128'),\n",
      "('86.38.26.84:6249'),\n",
      "('104.207.50.208:3128'),\n",
      "('104.207.44.87:3128'),\n",
      "('156.228.85.228:3128'),\n",
      "('156.228.79.214:3128'),\n",
      "('156.228.79.241:3128'),\n",
      "('156.228.117.190:3128'),\n",
      "('31.57.41.180:5756'),\n",
      "('156.228.86.218:3128'),\n",
      "('104.207.34.97:3128'),\n",
      "('104.207.37.54:3128'),\n",
      "('104.207.46.83:3128'),\n",
      "('104.207.32.28:3128'),\n",
      "('156.228.94.139:3128'),\n",
      "('104.207.62.126:3128'),\n",
      "('156.228.117.140:3128'),\n",
      "('156.228.92.133:3128'),\n",
      "('45.43.64.47:6305'),\n",
      "('156.228.97.41:3128'),\n",
      "('104.207.44.158:3128'),\n",
      "('107.181.148.51:5911'),\n",
      "('45.43.70.248:6535'),\n",
      "('154.214.1.45:3128'),\n",
      "('104.207.35.91:3128'),\n",
      "('156.228.86.140:3128'),\n",
      "('156.228.113.21:3128'),\n",
      "('156.228.98.30:3128'),\n",
      "('104.207.46.67:3128'),\n",
      "('217.69.121.222:5887'),\n",
      "('156.228.103.39:3128'),\n",
      "('31.58.18.70:6339'),\n",
      "('156.228.94.53:3128'),\n",
      "('156.228.117.98:3128'),\n",
      "('104.207.37.175:3128'),\n",
      "('104.207.52.18:3128'),\n",
      "('104.207.36.234:3128'),\n",
      "('104.207.42.37:3128'),\n",
      "('156.228.92.243:3128'),\n",
      "('104.207.33.10:3128'),\n",
      "('156.228.76.51:3128'),\n",
      "('104.207.46.10:3128'),\n",
      "('104.207.33.38:3128'),\n",
      "('104.207.55.105:3128'),\n",
      "('104.207.42.55:3128'),\n",
      "('156.228.77.255:3128'),\n",
      "('104.207.35.247:3128'),\n",
      "('156.228.102.197:3128'),\n",
      "('156.228.113.145:3128'),\n",
      "('156.228.79.216:3128'),\n",
      "('156.228.81.132:3128'),\n",
      "('31.57.82.91:6672'),\n",
      "('156.228.78.131:3128'),\n",
      "('156.228.79.240:3128'),\n",
      "('31.58.18.198:6467'),\n",
      "('104.207.41.34:3128'),\n",
      "('104.207.57.50:3128'),\n",
      "('104.207.48.143:3128'),\n",
      "('156.228.107.63:3128'),\n",
      "('156.228.82.94:3128'),\n",
      "('156.228.93.153:3128'),\n",
      "('104.207.42.32:3128'),\n",
      "('104.239.13.234:6863'),\n",
      "('156.228.107.211:3128'),\n",
      "('156.228.89.196:3128'),\n",
      "('156.228.92.11:3128'),\n",
      "('104.207.50.210:3128'),\n",
      "('156.228.117.138:3128'),\n",
      "('156.228.82.158:3128'),\n",
      "('156.228.124.198:3128'),\n",
      "('156.228.102.72:3128'),\n",
      "('107.181.148.152:6012'),\n",
      "('104.207.50.201:3128'),\n",
      "('104.207.45.237:3128'),\n",
      "('156.228.115.145:3128'),\n",
      "('156.228.76.222:3128'),\n",
      "('156.228.92.15:3128'),\n",
      "('104.207.42.42:3128'),\n",
      "('156.228.91.78:3128'),\n",
      "('104.207.48.81:3128'),\n",
      "('156.228.118.82:3128'),\n",
      "('67.43.227.227:18213'),\n",
      "('203.115.101.53:82'),\n",
      "('72.10.160.173:19837'),\n",
      "('116.203.139.209:5678'),\n",
      "('188.166.197.129:3128'),\n",
      "('65.108.159.129:8080'),\n",
      "('72.10.160.91:13219'),\n",
      "('85.215.64.49:80'),\n",
      "('50.207.199.87:80'),\n",
      "('178.63.17.240:10095'),\n",
      "('13.36.104.85:80'),\n",
      "('13.36.87.105:3128'),\n",
      "('50.232.104.86:80'),\n",
      "('50.207.199.82:80'),\n",
      "('66.191.31.158:80'),\n",
      "('54.67.125.45:3128'),\n",
      "('185.212.60.62:80'),\n",
      "('13.208.56.180:80'),\n",
      "('3.37.125.76:3128'),\n",
      "('3.127.62.252:80'),\n",
      "('18.228.149.161:80'),\n",
      "('3.139.242.184:80'),\n",
      "('54.233.119.172:3128'),\n",
      "('116.125.141.115:80'),\n",
      "('3.129.184.210:80'),\n",
      "('51.16.199.206:3128'),\n",
      "('52.63.129.110:3128'),\n",
      "('15.156.24.206:3128'),\n",
      "('51.17.58.162:3128'),\n",
      "('3.97.176.251:3128'),\n",
      "('51.20.19.159:3128'),\n",
      "('3.212.148.199:3128'),\n",
      "('54.152.3.36:80'),\n",
      "('113.160.132.195:8080'),\n",
      "('47.88.59.79:82'),\n",
      "('44.219.175.186:80'),\n",
      "('216.229.112.25:8080'),\n",
      "('192.73.244.36:80'),\n",
      "('198.49.68.80:80'),\n",
      "('116.203.36.93:3128'),\n",
      "('13.38.153.36:80'),\n",
      "('13.37.73.214:80'),\n",
      "('23.247.136.245:80'),\n",
      "('3.123.150.192:80'),\n",
      "('3.78.92.159:3128'),\n",
      "('54.179.39.14:3128'),\n",
      "('8.215.105.127:7777'),\n",
      "('141.11.103.136:8080'),\n",
      "('97.74.87.226:80'),\n",
      "('104.207.32.75:3128'),\n",
      "('156.228.114.100:3128'),\n",
      "('104.207.37.211:3128'),\n",
      "('104.207.46.136:3128'),\n",
      "('156.228.100.254:3128'),\n",
      "('156.228.99.96:3128'),\n",
      "('156.228.92.162:3128'),\n",
      "('156.228.124.84:3128'),\n",
      "('156.228.109.49:3128'),\n",
      "('104.207.32.121:3128'),\n",
      "('45.43.81.196:5843'),\n",
      "('156.228.78.203:3128'),\n",
      "('156.228.81.10:3128'),\n",
      "('45.135.139.163:6466'),\n",
      "('156.228.107.80:3128'),\n",
      "('104.207.33.140:3128'),\n",
      "('104.207.47.92:3128'),\n",
      "('156.228.106.96:3128'),\n",
      "('156.228.95.13:3128'),\n",
      "('156.228.91.98:3128'),\n",
      "('156.228.96.26:3128'),\n",
      "('104.207.46.171:3128'),\n",
      "('104.207.35.201:3128'),\n",
      "('162.220.246.155:6439'),\n",
      "('104.207.43.191:3128'),\n",
      "('156.228.95.18:3128'),\n",
      "('156.228.125.109:3128'),\n",
      "('104.207.40.168:3128'),\n",
      "('198.105.111.90:6768'),\n",
      "('104.207.38.1:3128'),\n",
      "('162.220.247.121:6716'),\n",
      "('104.207.42.1:3128'),\n",
      "('156.228.100.230:3128'),\n",
      "('156.228.114.38:3128'),\n",
      "('104.207.37.40:3128'),\n",
      "('104.207.58.14:3128'),\n",
      "('104.207.40.63:3128'),\n",
      "('156.228.102.150:3128'),\n",
      "('104.207.38.182:3128'),\n",
      "('156.228.82.68:3128'),\n",
      "('104.207.34.151:3128'),\n",
      "('156.228.106.174:3128'),\n",
      "('86.38.26.179:6344'),\n",
      "('156.228.105.189:3128'),\n",
      "('156.228.108.234:3128'),\n",
      "('156.228.78.62:3128'),\n",
      "('104.207.33.169:3128'),\n"
     ]
    }
   ],
   "source": [
    "print(f\"INSERT INTO {TABLE_NAME} (ip)\\nVALUES\")\n",
    "for r in result:\n",
    "    print(f\"('{r}'),\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-21 11:19:15.910998\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "access_key = \"AKIASUM32O4JDM5A2KTM\"\n",
    "secret_key = \"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\"\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "\n",
    "s3.put_object(\n",
    "    Body=json.dumps(result),\n",
    "    Bucket=\"mysamplebucket001036\",\n",
    "    Key=\"proxy_ip\"\n",
    ")\n",
    "\n",
    "ips = s3.get_object(\n",
    "    Bucket=\"mysamplebucket001036\",\n",
    "    Key=\"proxy_ip\"\n",
    ")['Body'].read().decode(\"utf-8\")\n",
    "ips = json.loads(ips)\n",
    "\n",
    "print(datetime.datetime.fromisoformat(ips[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import boto3\n",
    "import smart_open\n",
    "import openai\n",
    "\n",
    "from settings import (\n",
    "    DB_HOST,\n",
    "    DB_NAME,\n",
    "    DB_USER,\n",
    "    DB_PASSWORD,\n",
    "    DB_PORT,\n",
    "    VIEW_THRESHOLD,\n",
    "    OPENAI_API_KEY,\n",
    "    S3_BUCKET,\n",
    ")\n",
    "\n",
    "json_match_ptrn = re.compile(r'\\{.*\\}')\n",
    "# 전역 변수로 connection 관리\n",
    "db_conn = None\n",
    "\n",
    "def get_db_connection():\n",
    "    global db_conn\n",
    "    \n",
    "    # 기존 연결이 있고 유효한지 확인\n",
    "    if db_conn is not None:\n",
    "        try:\n",
    "            # 간단한 쿼리로 연결 상태 확인\n",
    "            with db_conn.cursor() as cur:\n",
    "                cur.execute('SELECT 1')\n",
    "            return db_conn\n",
    "        except Exception:\n",
    "            # 연결이 끊어졌다면 None으로 설정\n",
    "            db_conn = None\n",
    "    \n",
    "    # 새로운 연결 생성\n",
    "    try:\n",
    "        if db_conn is None:\n",
    "            db_conn = psycopg2.connect(\n",
    "                host=DB_HOST,\n",
    "                database=DB_NAME,\n",
    "                user=DB_USER,\n",
    "                password=DB_PASSWORD,\n",
    "                port=DB_PORT,\n",
    "                cursor_factory=psycopg2.extras.RealDictCursor,  # 기본 cursor factory 설정\n",
    "                # Timeout 설정 추가\n",
    "                connect_timeout=5,        # 연결 시도 timeout (초)\n",
    "                keepalives=1,            # TCP keepalive 활성화\n",
    "                keepalives_idle=1800,      # TCP keepalive idle time (초)\n",
    "                keepalives_interval=10,   # TCP keepalive interval (초)\n",
    "                keepalives_count=3       # TCP keepalive retry count            \n",
    "            )\n",
    "            db_conn.autocommit = True  # 필요에 따라 설정\n",
    "    except Exception as e:\n",
    "        print(f\"DB 연결 에러: {e}\")\n",
    "        return None\n",
    "\n",
    "    return db_conn\n",
    "\n",
    "# 전역 변수로 s3_client 관리\n",
    "s3_client = None\n",
    "\n",
    "def get_s3_client():\n",
    "    global s3_client\n",
    "\n",
    "    if s3_client is not None:\n",
    "        return s3_client\n",
    "\n",
    "    try:\n",
    "        s3_client = boto3.client('s3')\n",
    "    except Exception as e:\n",
    "        print(f\"S3 클라이언트 생성 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "    return s3_client\n",
    "\n",
    "def get_search_keywords(\n",
    "        conn,\n",
    "        keyword_set_name: str,\n",
    "    ) -> Optional[List[str]]:\n",
    "    \"\"\"\n",
    "    이후에 airflow DAG에서 사용할 수 있도록 키워드들을 함수로 분리합니다.\n",
    "\n",
    "    병렬 search 작업을 위해 키워드 세트를 가져옵니다.\n",
    "    Args:\n",
    "        conn: PostgreSQL 데이터베이스 연결 객체\n",
    "        keyword_set_name: 키워드 세트 이름\n",
    "    \n",
    "    Returns:\n",
    "        키워드 리스트\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = f\"\"\"\n",
    "        SELECT \n",
    "            keywords\n",
    "        FROM \n",
    "            keyword_set\n",
    "        WHERE\n",
    "            name = '{keyword_set_name}'            \n",
    "        \"\"\"\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchone()\n",
    "        if result is None:\n",
    "            return None\n",
    "        return result['keywords']\n",
    "        \n",
    "\n",
    "def upsert_post_tracking_data(\n",
    "        conn,\n",
    "        table_name, \n",
    "        payload: Dict\n",
    "        ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    한 포스팅을 search 단계에서 파싱할 때 마다 불러와야 합니다.\n",
    "\n",
    "    1. 실패 혹은 차단된 경우: url, status, checked_at 필드가 필요합니다.\n",
    "    2. 새로운 것 들어올 때: 모든 payload 필드가 필요합니다.\n",
    "    2. 기존 것 업데이트: url, status, comment_count, view, created_at, checked_at, keyword 필드가 필요합니다.\n",
    "    \n",
    "    payload: {\n",
    "        url: str,\n",
    "        post_id: str,\n",
    "        status: str (CHANGED, UNCHANGED, FAILED, BANNED) (실패 혹은 차단된 경우 필요)\n",
    "        comment_count: int,\n",
    "        view: int,\n",
    "        created_at: datetime,\n",
    "        checked_at: datetime, 실패 혹은 차단된 경우에도 필요.\n",
    "        keyword: str,\n",
    "    }\n",
    "    \n",
    "    return None: 실패, True: 성공\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert isinstance(payload['url'], str), \"url은 문자열이어야 합니다.\"\n",
    "        assert isinstance(payload['checked_at'], datetime), \"checked_at은 datetime 객체여야 합니다.\"\n",
    "        url = payload.get('url')\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = f\"SELECT * FROM {table_name} WHERE url = %s\"\n",
    "            cursor.execute(\n",
    "                sql,\n",
    "                (url,)\n",
    "                )\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "\n",
    "            if result is None:\n",
    "                print(f\"[INFO] 새로운 데이터: {url}\")\n",
    "                assert isinstance(payload['post_id'], str), \"post_id는 문자열이여야 합니다.\"\n",
    "                assert isinstance(payload['status'], str), \"status는 문자열이어야 합니다.\"\n",
    "                assert isinstance(payload['comment_count'], int), \"comment_count는 정수여야 합니다.\"\n",
    "                assert isinstance(payload['view'], int), \"view는 정수여야 합니다.\"\n",
    "                assert isinstance(payload['created_at'], datetime), \"created_at은 datetime 객체여야 합니다.\"\n",
    "                assert isinstance(payload['keyword'], str), \"keyword은 문자열이어야 합니다.\"\n",
    "                sql = f\"\"\"\n",
    "                INSERT INTO {table_name} (\n",
    "                    url,\n",
    "                    post_id,\n",
    "                    status,\n",
    "                    comment_count,\n",
    "                    view,\n",
    "                    created_at,\n",
    "                    checked_at,\n",
    "                    keywords\n",
    "                ) VALUES (\n",
    "                    %s, %s, %s, %s, %s, %s, %s, ARRAY[%s]::TEXT[]\n",
    "                )\n",
    "                \"\"\"\n",
    "                cursor.execute(\n",
    "                    sql,\n",
    "                    (\n",
    "                        url,\n",
    "                        payload['post_id'],\n",
    "                        payload['status'],\n",
    "                        payload['comment_count'],\n",
    "                        payload['view'],\n",
    "                        payload['created_at'],\n",
    "                        payload['checked_at'],\n",
    "                        payload['keyword'],\n",
    "                    )\n",
    "                )\n",
    "            else:                \n",
    "                assert isinstance(payload['status'], str), \"status는 문자열이어야 합니다.\"\n",
    "                unstable_status = payload['status'] in [\"FAILED\", \"BANNED\"]\n",
    "                if unstable_status:\n",
    "                    print(f\"[WARN] 크롤링 문제 발생 / 상태 업데이트 / 기존 데이터: {url}\")\n",
    "                    if payload['status'] == \"FAILED\":                        \n",
    "                        update_status_failed(conn, table_name, url, payload['checked_at'])\n",
    "                    elif payload['status'] == \"BANNED\":\n",
    "                        update_status_banned(conn, table_name, url, payload['checked_at'])\n",
    "                    return True\n",
    "                \n",
    "                assert isinstance(payload['comment_count'], int), \"comment_count는 정수여야 합니다.\"\n",
    "                assert isinstance(payload['view'], int), \"view는 정수여야 합니다.\"\n",
    "                assert isinstance(payload['keyword'], str), \"keyword은 문자열이어야 합니다.\"\n",
    "                has_valuable_change = (\n",
    "                    result['view'] - payload['view'] > VIEW_THRESHOLD\n",
    "                    or result['comment_count'] > payload['comment_count']\n",
    "                )\n",
    "                new_keyword_event = payload['keyword'] != \"\" and payload['keyword'] not in result['keywords']\n",
    "                if has_valuable_change or new_keyword_event:\n",
    "                    print(f\"[INFO] 업데이트 시행 / 기존 데이터: {url}\")\n",
    "                    sql = f\"\"\"\n",
    "                    UPDATE {table_name}\n",
    "                    SET\n",
    "                        status = %s,\n",
    "                        comment_count = %s,\n",
    "                        view = %s,\n",
    "                        created_at = %s,\n",
    "                        checked_at = %s,\n",
    "                        keywords = CASE \n",
    "                            WHEN %s = ANY(keywords) THEN keywords\n",
    "                            ELSE array_append(keywords, %s) \n",
    "                        END\n",
    "                    WHERE url = %s\n",
    "                    \"\"\"\n",
    "                    cursor.execute(\n",
    "                        sql,\n",
    "                        (\n",
    "                            payload['status'],\n",
    "                            payload['comment_count'],\n",
    "                            payload['view'],\n",
    "                            payload['created_at'],\n",
    "                            payload['checked_at'],\n",
    "                            payload['keyword'],\n",
    "                            payload['keyword'],\n",
    "                            url,\n",
    "                        )\n",
    "                    )\n",
    "                    conn.commit()\n",
    "                    return True                \n",
    "                \n",
    "                print(f\"[INFO] 업데이트 불필요 / 기존 데이터: {url}\")\n",
    "            \n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] DB 업데이트 에러: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def get_details_to_parse(\n",
    "        conn,\n",
    "        table_name,\n",
    "        total_rows: int = 1\n",
    "        ) -> Optional[List[Dict]]:\n",
    "    \"\"\"\n",
    "    detail 단계에서 처리할 url들을 가져옵니다.\n",
    "    [변경] 1개만 가져옵니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            total_rows = 1\n",
    "            sql = f\"\"\"\n",
    "            UPDATE {table_name}\n",
    "            SET status = 'UNCHANGED'\n",
    "            WHERE status = 'CHANGED'\n",
    "            AND id IN (\n",
    "                SELECT id \n",
    "                FROM {table_name}\n",
    "                WHERE status = 'CHANGED'\n",
    "                LIMIT {total_rows}\n",
    "            )\n",
    "            RETURNING *\n",
    "            \"\"\"\n",
    "            cursor.execute(sql)\n",
    "            \n",
    "            result = cursor.fetchall()\n",
    "            conn.commit()  # 변경사항을 저장하기 위해 commit 필요\n",
    "            for res in result:\n",
    "                res['status'] = \"CHANGED\"\n",
    "                \n",
    "            if result == []:\n",
    "                return []            \n",
    "            return result[0] # 현재 한 개이므로 1개만 반환\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] DB 조회 에러: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_search_status(\n",
    "       conn,\n",
    "       table_name: str,\n",
    "       url: str,\n",
    "       checked_at: Optional[datetime],\n",
    "       status: Optional[str] = None,\n",
    "       _prevent_direct_status: str = None  # 직접 status 파라미터를 받지 못하게 하는 파라미터\n",
    "    ) -> Optional[bool]:\n",
    "    \"\"\"DB 레코드의 상태를 업데이트하는 내부 함수입니다. 직접 호출하지 마세요.\n",
    "    대신 update_status_failed(), update_status_banned() 등의 함수를 사용하세요.\n",
    "\n",
    "    Args:\n",
    "        conn: PostgreSQL 데이터베이스 연결 객체\n",
    "        table_name: 업데이트할 테이블 이름\n",
    "        url: 업데이트할 레코드의 URL\n",
    "        checked_at: 확인일자\n",
    "        status: 업데이트할 상태\n",
    "\n",
    "    Returns:\n",
    "        성공 시 True, 실패 시 None\n",
    "    \"\"\"\n",
    "    if _prevent_direct_status is None:\n",
    "        raise ValueError(\"이 함수는 직접 호출하지 마세요. 대신 update_status_failed() 등을 사용하세요.\")\n",
    "       \n",
    "    with conn.cursor() as cursor:  # cursor() 메서드로 수정\n",
    "        try:\n",
    "            if checked_at is None:\n",
    "                    sql = f\"\"\"\n",
    "                    UPDATE {table_name}\n",
    "                    SET\n",
    "                        status = %s\n",
    "                    WHERE url = %s\n",
    "                    \"\"\"\n",
    "                    cursor.execute(\n",
    "                        sql,\n",
    "                        (\n",
    "                            status,\n",
    "                            url\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                    sql = f\"\"\"\n",
    "                    UPDATE {table_name}\n",
    "                    SET\n",
    "                        status = %s\n",
    "                        checked_at = %s\n",
    "                    WHERE url = %s\n",
    "                    \"\"\"\n",
    "                    cursor.execute(\n",
    "                        sql,\n",
    "                        (\n",
    "                            status,\n",
    "                            checked_at,\n",
    "                            url\n",
    "                        )\n",
    "                    )\n",
    "            conn.commit()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] DB status, checked_at 에러 / 테이블 이름: {table_name}, status: {status}, checked_at: {checked_at} / 에러 내용: {e}\")\n",
    "            return None\n",
    "\n",
    "def update_status_failed(\n",
    "        conn,\n",
    "        table_name: str,\n",
    "        url: str,\n",
    "        checked_at: Optional[datetime] = None\n",
    "        ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    detail 단계에서 실패한 url들을 업데이트합니다.\n",
    "    URL의 상태를 FAILED로 업데이트합니다.\n",
    "\n",
    "    Args:\n",
    "       conn: PostgreSQL 데이터베이스 연결 객체\n",
    "       table_name: 업데이트할 테이블 이름\n",
    "       url: 업데이트할 레코드의 URL\n",
    "\n",
    "    Returns:\n",
    "       성공 시 True, 실패 시 None\n",
    "    \"\"\"\n",
    "    return update_search_status(conn, table_name, url, checked_at, status=\"FAILED\", _prevent_direct_status=\"used\")\n",
    "\n",
    "def update_status_banned(\n",
    "        conn,\n",
    "        table_name: str,\n",
    "        url: str,\n",
    "        checked_at: Optional[datetime] = None\n",
    "        ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    detail 단계에서 차단된 url들을 업데이트합니다.\n",
    "    URL의 상태를 BANNED로 업데이트합니다.\n",
    "\n",
    "    Args:\n",
    "       conn: PostgreSQL 데이터베이스 연결 객체\n",
    "       table_name: 업데이트할 테이블 이름\n",
    "       url: 업데이트할 레코드의 URL\n",
    "\n",
    "    Returns:\n",
    "       성공 시 True, 실패 시 None\n",
    "    \"\"\"\n",
    "    return update_search_status(conn, table_name, url, checked_at, status=\"BANNED\", _prevent_direct_status=\"used\")\n",
    "\n",
    "def update_status_unchanged(\n",
    "        conn,\n",
    "        table_name: str,\n",
    "        url:str,\n",
    "        checked_at: Optional[datetime] = None\n",
    "        ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    detail 단계에서 완료된 url들을 업데이트합니다.\n",
    "    URL의 상태를 UNCHANGED로 업데이트합니다.\n",
    "\n",
    "    Args:\n",
    "       conn: PostgreSQL 데이터베이스 연결 객체\n",
    "       table_name: 업데이트할 테이블 이름\n",
    "       url: 업데이트할 레코드의 URL\n",
    "\n",
    "    Returns:\n",
    "       성공 시 True, 실패 시 None\n",
    "    \"\"\"\n",
    "    return update_search_status(conn, table_name, url, checked_at, status=\"UNCHANGED\", _prevent_direct_status=\"used\")\n",
    "\n",
    "def update_status_changed(\n",
    "        conn,\n",
    "        table_name: str,\n",
    "        url: str,\n",
    "        checked_at: Optional[datetime] = None\n",
    "        ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    detail 단계에서 변경된 url들을 업데이트합니다.\n",
    "    URL의 상태를 CHANGED로 업데이트합니다.\n",
    "\n",
    "    Args:\n",
    "       conn: PostgreSQL 데이터베이스 연결 객체\n",
    "       table_name: 업데이트할 테이블 이름\n",
    "       url: 업데이트할 레코드의 URL\n",
    "\n",
    "    Returns:\n",
    "       성공 시 True, 실패 시 None\n",
    "    \"\"\"\n",
    "    return update_search_status(conn, table_name, url, checked_at, status=\"CHANGED\", _prevent_direct_status=\"used\")\n",
    "\n",
    "def update_changed_stats(\n",
    "        conn,\n",
    "        table_name: str,\n",
    "        url: str,\n",
    "        comment_count: int,\n",
    "        view: int,\n",
    "        created_at: datetime,\n",
    "    ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    detail에서 변화된 포스트의 정보를 업데이트합니다.\n",
    "    UNCHANGED로 변경도 진행합니다.\n",
    "    Args:\n",
    "       conn: PostgreSQL 데이터베이스 연결 객체\n",
    "       table_name: 업데이트할 테이블 이름\n",
    "       url: 업데이트할 레코드의 URL\n",
    "       comment_count: 댓글 수\n",
    "       view: 조회수\n",
    "       created_at: 작성시간\n",
    "       checked_at: 확인일자\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cursor:\n",
    "        try:\n",
    "            sql = f\"\"\"\n",
    "            UPDATE {table_name}\n",
    "            SET\n",
    "                comment_count = %s,\n",
    "                view = %s,\n",
    "                created_at = %s,\n",
    "                status = 'UNCHANGED'\n",
    "            WHERE url = %s\n",
    "            \"\"\"\n",
    "            cursor.execute(\n",
    "                sql,\n",
    "                (\n",
    "                    comment_count,\n",
    "                    view,\n",
    "                    created_at,\n",
    "                    url\n",
    "                )\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] comment_count, view 수정 에러: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "def log_crawling_metadata(\n",
    "        conn,\n",
    "        checked_at: datetime,\n",
    "        keywords_str: str,\n",
    "        platform: str,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    checked_at: datetime 객체\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = f\"\"\"\n",
    "            INSERT INTO crawling_metadata (\n",
    "                checked_at,\n",
    "                keywords_str,\n",
    "                platform,\n",
    "                bucket_name\n",
    "            ) VALUES (\n",
    "                %s, %s, %s, %s\n",
    "            )\n",
    "            \"\"\"\n",
    "            cursor.execute(\n",
    "                sql,\n",
    "                (\n",
    "                    checked_at,\n",
    "                    keywords_str,\n",
    "                    platform,\n",
    "                    S3_BUCKET\n",
    "                )\n",
    "            )\n",
    "            conn.commit()\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] DB 메타데이터 로깅 에러: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "\n",
    "def save_s3_bucket_by_parquet(\n",
    "        checked_at_dt: datetime,\n",
    "        platform: str,\n",
    "        data: List[Dict],\n",
    "        id: str,\n",
    "    ) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    checked_at_dt: datetime 객체\n",
    "\n",
    "    platform: 적용한 플랫폼\n",
    "    \n",
    "    data: [ # 포스팅\n",
    "        {\n",
    "        플랫폼 \"platform\"\n",
    "        검색 키워드 “keyword”\n",
    "        포스트 id “post_id”\n",
    "        제목 \"title\"\n",
    "        url:  \"url\"\n",
    "        내용 \"content\"\n",
    "        조회수 \"view\"\n",
    "        작성일자 \"created_at\"\n",
    "        좋아요 수 \"like\"\n",
    "        싫어요 수 \"dislike\"\n",
    "        댓글수 (웹페이지 기반): \"comment_count\"\n",
    "        댓글: [ {\n",
    "        # 댓글 \"comment\"\n",
    "        작성일자: \"created_at\"\n",
    "        내용: \"content\"\n",
    "        좋아요 수: \"like\"\n",
    "        싫어요 수: \"dislike\"\n",
    "        },\n",
    "        {\n",
    "        ...\n",
    "        },\n",
    "        ]\n",
    "        },\n",
    "        ...                \n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "    s3_client = get_s3_client()\n",
    "\n",
    "    if s3_client is None:\n",
    "        print(\"[ERROR] S3 클라이언트 생성 실패\")\n",
    "        return None\n",
    "    \n",
    "    date = checked_at_dt.date().strftime(\"%Y-%m-%d\")\n",
    "    hour = str(checked_at_dt.hour)\n",
    "    minute = str(checked_at_dt.minute)\n",
    "\n",
    "    # 코멘트 데이터\n",
    "    keywords_posts = defaultdict(list)\n",
    "    keywords_comments = defaultdict(list)\n",
    "\n",
    "    for post in data:\n",
    "        # 코멘트 제거\n",
    "        post.pop('id', None)\n",
    "        post.pop('status', None)\n",
    "        post.pop('checked_at', None)\n",
    "        post['platform'] = platform\n",
    "        post['checked_at'] = checked_at_dt\n",
    "        try:\n",
    "            post['like'] = int(post['like'])\n",
    "        except:\n",
    "            post['like'] = None\n",
    "        try:\n",
    "            post['dislike'] = int(post['dislike']) \n",
    "        except:\n",
    "            post['dislike'] = None\n",
    "        post['comment_count'] = int(post['comment_count'])\n",
    "        post['view'] = int(post['view'])\n",
    "        post_comments = post.pop('comment', [])\n",
    "        keywords = post.get('keywords', [\"no_keyword\"])\n",
    "        post['keywords'] = \"|\".join(keywords).replace(\" \", \"_\")\n",
    "        joined_keywords = \"-\".join((keywords))\n",
    "        keywords_posts[joined_keywords].append(post)\n",
    "        # post_id를 기준으로 연결\n",
    "        for comment in post_comments:\n",
    "            comment['post_id'] = post['post_id']\n",
    "            # 좋아요, 싫어요 수가 없는 경우 None으로 처리\n",
    "            comment['checked_at'] = checked_at_dt\n",
    "            try:\n",
    "                comment['like'] = int(comment['like'])\n",
    "            except:\n",
    "                comment['like'] = None            \n",
    "            try:\n",
    "                comment['dislike'] = int(comment['dislike'])\n",
    "            except:\n",
    "                comment['dislike'] = None\n",
    "            keywords_comments[joined_keywords].append(comment)\n",
    "   # 게시물 스키마 정의\n",
    "    posts_schema = pa.schema([\n",
    "        ('platform', pa.string()),\n",
    "        ('title', pa.string()),\n",
    "        ('post_id', pa.string()),\n",
    "        ('url', pa.string()),\n",
    "        ('content', pa.string()),\n",
    "        ('view', pa.int64()),\n",
    "        ('created_at', pa.timestamp('s')),  # 'ns' 대신 's' 사용\n",
    "        ('like', pa.int64()),\n",
    "        ('dislike', pa.int64()),\n",
    "        ('comment_count', pa.int64()),\n",
    "        ('keywords', pa.string()),\n",
    "        ('sentiment', pa.string()),\n",
    "    ])\n",
    "\n",
    "    # 댓글 스키마 정의\n",
    "    comments_schema = pa.schema([\n",
    "        ('created_at', pa.timestamp('s')),  # 'ns' 대신 's' 사용\n",
    "        ('content', pa.string()),\n",
    "        ('like', pa.int64()),\n",
    "        ('dislike', pa.int64()),\n",
    "        ('post_id', pa.string()),\n",
    "        ('sentiment', pa.string()),\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        for keyword, posts in keywords_posts.items():\n",
    "            # Parquet로 변환\n",
    "            posts_table = pa.Table.from_pylist(posts, schema=posts_schema)\n",
    "            comments_table = pa.Table.from_pylist(keywords_comments[keyword], schema=comments_schema)\n",
    "\n",
    "            # S3 업로드 경로 설정\n",
    "            s3_posts_key = f\"{date}/{hour}/{minute}/{keyword}/{id}_{platform}_posts.parquet\"\n",
    "            s3_comments_key = f\"{date}/{hour}/{minute}/{keyword}/{id}_{platform}_comments.parquet\"\n",
    "\n",
    "            # 게시물 데이터 업로드\n",
    "            with smart_open.open(f\"s3://{S3_BUCKET}/{s3_posts_key}\", \"wb\") as s3_file:\n",
    "                pq.write_table(posts_table, s3_file, compression='snappy')            \n",
    "            \n",
    "            # 댓글 데이터 업로드\n",
    "            with smart_open.open(f\"s3://{S3_BUCKET}/{s3_comments_key}\", \"wb\") as s3_file:\n",
    "                pq.write_table(comments_table, s3_file, compression='snappy')\n",
    "            \n",
    "            print(f\"[INFO] S3 업로드 완료 (키워드: {keyword}): {s3_posts_key}, {s3_comments_key}\")\n",
    "            log_crawling_metadata(conn, checked_at_dt, keyword, platform)\n",
    "\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] S3 업로드 실패: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return None    \n",
    "\n",
    "def get_my_ip():\n",
    "    try:\n",
    "        # Option 1: Using ipify API\n",
    "        response = requests.get('https://api.ipify.org')\n",
    "        print(f\"[INFO] AWS NAT Gateway 변환 이후 IP: {response.text.strip()}\")\n",
    "    except:\n",
    "        try:\n",
    "            # Option 2: Alternative IP service if ipify fails\n",
    "            response = requests.get('https://checkip.amazonaws.com')\n",
    "            print(f\"[INFO] AWS NAT Gateway 변환 이후 IP: {response.text.strip()}\")\n",
    "        except:\n",
    "            return \"Failed to get IP address\"\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    GPT 응답에서 JSON 부분만 추출하고 정리하는 함수.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        clean_text = re.sub(r\"```json\\s*([\\s\\S]*?)\\s*```\", r\"\\1\", response_text.strip())\n",
    "        return json.loads(clean_text)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ JSON 디코딩 실패: {e}\\nGPT 응답: {response_text}\")\n",
    "        return None\n",
    "\n",
    "def analyze_post_with_gpt(post):\n",
    "    \"\"\"\n",
    "    GPT API를 이용해 게시글 및 댓글의 감정 분석을 수행하고 원본 데이터를 업데이트하는 함수.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        title = post.get(\"title\", \"제목 없음\")\n",
    "        content = post.get(\"content\", \"본문 없음\")\n",
    "        comments = post.get(\"comment\", [])\n",
    "\n",
    "        comment_texts = \"\\n\".join([f\"- {c['content']}\" for c in comments])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        아래 게시글 내용을 분석하여 감정 분석(sentiment analysis)을 수행하세요.\n",
    "\n",
    "        제목: {title}\n",
    "        본문: {content}\n",
    "        댓글:\n",
    "        {comment_texts}\n",
    "\n",
    "        분석할 내용:\n",
    "        1. **게시글 감정 분석**: 게시글의 감정을 title와 content를 이용해서 '벤츠'라는 단어를 기준으로 '긍정/부정/중립' 중 하나로 판단하세요.\n",
    "        2. **댓글 감정 분석**: 각 댓글의 감정을 title, content, comment_texts와 게시글 감정을 참고하여 '벤츠'라는 단어를 기준으로 '긍정/부정/중립'으로 분류하세요.\n",
    "\n",
    "        **반드시 JSON 형식으로 답변하세요.**\n",
    "        JSON 형식:\n",
    "        {{\n",
    "            \"게시글 감정\": \"positive/negative/neutral\",\n",
    "            \"comment_sentiments\": [\n",
    "                {{\"내용\": \"댓글1 내용\", \"감정\": \"positive/negative/neutral\"}},\n",
    "                {{\"내용\": \"댓글2 내용\", \"감정\": \"positive/negative/neutral\"}}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[{\"role\": \"system\", \"content\": \"너는 JSON 응답을 제공하는 AI야.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        gpt_output = response.choices[0].message.content.strip()\n",
    "        print(f\"📌 GPT 응답 내용: {gpt_output}\")\n",
    "\n",
    "        if not gpt_output:\n",
    "            raise ValueError(\"GPT 응답이 비어 있습니다.\")\n",
    "\n",
    "        analysis_result = extract_json_from_response(gpt_output)\n",
    "        if not analysis_result:\n",
    "            print(\"❌ 감정 분석 실패: JSON 응답을 파싱할 수 없습니다.\")\n",
    "            return post\n",
    "\n",
    "        # 게시글 감정 분석 결과 추가\n",
    "        post[\"sentiment\"] = analysis_result.get(\"게시글 감정\", \"neutral\")\n",
    "\n",
    "        # 댓글 감정 분석 결과 추가\n",
    "        if \"comment_sentiments\" in analysis_result:\n",
    "            for com, gpts in zip(post[\"comment\"], analysis_result[\"comment_sentiments\"]):\n",
    "                com[\"sentiment\"] = gpts[\"감정\"]\n",
    "\n",
    "        return post\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPT API 호출 오류: {e}\")\n",
    "        return post  # 오류 발생 시 원본 데이터 반환\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Table \"Proxy_ip\"\n",
    "|-----|----------|------------|-------|--------------|\n",
    "| IP  | dcmotors | Bobaedream | Clien | Availability |\n",
    "|-----|----------|------------|-------|--------------|\n",
    "| str | \"NONE\" or \"USING\" or \"BANNED\" | True/False   |\n",
    "|     | type: varchar(8)              | boolean type |\n",
    "|-----|----------|------------|-------|--------------|\n",
    "\"\"\"\n",
    "\n",
    "def update_proxy_table() -> bool:\n",
    "    \"\"\"ip proxy table을 업데이트 하는 내부 함수입니다.\n",
    "    외부 사이트로부터 프록시 데이터를 받아와서 ip 테이블에 업데이트 합니다.\n",
    "    사용중인 IP는 우선 USING_TEMP로 바꾸고 이후 IP를 반환 받으면서 처리합니다.\n",
    "\n",
    "    Returns:\n",
    "        업데이트를 했는데 추가된 행이 없으면 False 반환\n",
    "        그렇지 않으면 True 반환\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # get the page\n",
    "        url = \"https://free-proxy-list.net/#\"\n",
    "        response = requests.get(url)\n",
    "        assert response.status_code == 200, f\"updateProxyTable - Error! - status code:{response.status_code}\"\n",
    "        \n",
    "        # find ip by pattern\n",
    "        pattern = r\"(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}):(\\d+)\"\n",
    "        matches = re.findall(pattern, str(response.content))\n",
    "        ips = [f\"{ip}:{port}\" for ip, port in matches]\n",
    "        \n",
    "        updated = False\n",
    "        with db_conn.cursor() as cur:\n",
    "            # 각 IP에 대해 중복 체크 후 새로운 IP만 추가\n",
    "            for ip in ips:\n",
    "                # 중복 체크\n",
    "                cur.execute(\"\"\"\n",
    "                    SELECT ip FROM proxy_ip WHERE ip = %s\n",
    "                \"\"\", (ip,))\n",
    "                \n",
    "                if cur.fetchone() is None:\n",
    "                    # 새로운 IP 추가\n",
    "                    cur.execute(\"\"\"\n",
    "                        INSERT INTO proxy_ip (ip, dcmotors, bobaedream, clien, availability)\n",
    "                        VALUES (%s, 'NONE', 'NONE', 'NONE', TRUE)\n",
    "                    \"\"\", (ip,))\n",
    "                    updated = True\n",
    "            \n",
    "            db_conn.commit()\n",
    "        return updated\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 프록시 테이블 업데이트 실패: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def get_proxy_ip(platform: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"프록시 ip하나를 데이터 베이스로부터 얻어와 하나를 보내주는 함수입니다.\n",
    "    requests에서 사용하기 편하도록 딕셔너리 형태로 반환합니다.\n",
    "    가용 가능한 ip가 없으면 update proxy table 함수를 실행해서 새로운 ip를 얻습니다.\n",
    "\n",
    "    Args:\n",
    "        platform: 사용할 플랫폼 ('bobaedream' 또는 'clien')\n",
    "\n",
    "    Returns:\n",
    "        requests proxy 헤더 반환 딕셔너리 또는 None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with db_conn.cursor() as cur:\n",
    "            # 플랫폼에 따른 컬럼 선택\n",
    "            platform = platform.lower()\n",
    "            if platform not in ['dcmotors', 'bobaedream', 'clien']:\n",
    "                raise ValueError(\"Invalid platform\")\n",
    "                \n",
    "            # 사용 가능한 IP 찾기\n",
    "            cur.execute(f\"\"\"\n",
    "                UPDATE proxy_ip \n",
    "                SET {platform} = 'USING'\n",
    "                WHERE ip = (\n",
    "                    SELECT ip \n",
    "                    FROM proxy_ip \n",
    "                    WHERE availability = TRUE \n",
    "                    AND {platform} = 'NONE'\n",
    "                    LIMIT 1\n",
    "                )\n",
    "                RETURNING ip\n",
    "            \"\"\")\n",
    "            \n",
    "            result = cur.fetchone() # 무조건 딕셔너리\n",
    "            db_conn.commit()\n",
    "            \n",
    "            # 사용 가능한 IP가 없으면 새로운 IP들을 추가\n",
    "            if result is None:\n",
    "                if update_proxy_table():\n",
    "                    return get_proxy_ip(platform)  # 재귀적으로 다시 시도\n",
    "                return None\n",
    "                \n",
    "            return {\"http\": result['ip']}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 프록시 IP 가져오기 실패: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def return_proxy_ip(ip: str, platform: str, isBanned: bool, isTimeout: bool) -> None:\n",
    "    \"\"\"사용이 끝난 ip를 반환 받아 data table에 업데이트 합니다.\n",
    "\n",
    "    Args:\n",
    "        ip: 사용한 IP\n",
    "        platform: 사용한 플랫폼 ('bobaedream' 또는 'clien')\n",
    "        isBanned: 플랫폼 사이트 밴 여부\n",
    "        isTimeout: 프록시 IP 사용 가능 여부\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with db_conn.cursor() as cur:\n",
    "            if platform not in ['dcmotors', 'bobaedream', 'clien']:\n",
    "                raise ValueError(\"Invalid platform\")\n",
    "                \n",
    "            # 상태 업데이트\n",
    "            status = \"BANNED\" if isBanned else \"NONE\"\n",
    "            \n",
    "            cur.execute(f\"\"\"\n",
    "                UPDATE proxy_ip \n",
    "                SET \n",
    "                    {platform} = %s,\n",
    "                    availability = %s\n",
    "                WHERE ip = %s\n",
    "            \"\"\", (status, not isTimeout, ip))\n",
    "            \n",
    "            db_conn.commit()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 프록시 IP 반환 실패: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.parse\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError\n",
    "\n",
    "from common_utils import (\n",
    "    get_db_connection,\n",
    "    save_s3_bucket_by_parquet,\n",
    "    upsert_post_tracking_data,\n",
    "    get_details_to_parse,\n",
    "    update_status_banned,\n",
    "    update_status_changed,\n",
    "    update_status_unchanged,\n",
    "    update_changed_stats,\n",
    "    analyze_post_with_gpt,\n",
    "    get_my_ip,\n",
    "    get_proxy_ip,\n",
    "    return_proxy_ip,\n",
    ")\n",
    "\n",
    "BASIC_URL = \"http://www.clien.net/service/search?q={query}&sort=recency&p={page_num}&boardCd=&isBoard=false\"\n",
    "CLIEN_URL = \"http://www.clien.net\"\n",
    "\n",
    "SEARCH_TABLE = \"probe_clien\"\n",
    "\n",
    "EXECUTOR_MAX = 20\n",
    "REMAINING_TIME_LIMIT = 60000 # ms, milli-second\n",
    "\n",
    "# 멀티스레드를 위한 설정\n",
    "analysis_executor = ThreadPoolExecutor(max_workers=EXECUTOR_MAX)\n",
    "\n",
    "def detail(event, context):\n",
    "# parameters\n",
    "    lambda_id = event.get(\"id\")\n",
    "    \n",
    "    get_my_ip()\n",
    "    \n",
    "    all_post = []\n",
    "    futures = []\n",
    "\n",
    "    executing = 0\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "    }\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    if conn is None:\n",
    "        print(\"[ERROR] DB 연결 실패\")\n",
    "        return  {\n",
    "            \"status_code\": 500, \n",
    "            \"body\": \"[ERROR] DETAIL/clien DB 연결 실패\"\n",
    "        }\n",
    "    \n",
    "    return_dict = {\n",
    "        \"status_code\": 204,\n",
    "        \"body\": \"[INFO] clien DETAIL / 파싱할 데이터가 없습니다.\"\n",
    "    }\n",
    "\n",
    "    # DB에서 상세 정보를 가져올 게시물 목록\n",
    "    table_name = 'probe_clien'\n",
    "\n",
    "    while True:\n",
    "        detail = get_details_to_parse(conn, table_name)\n",
    "        if detail is None:\n",
    "            print(\"[ERROR] DB 조회 실패\")\n",
    "            return_dict[\"status_code\"] = 500\n",
    "            return_dict[\"body\"] = \"[ERROR] DETAIL/clien DB 조회 실패\"\n",
    "            break\n",
    "    \n",
    "        if detail == []:\n",
    "            print(\"[INFO] 파싱할 게시물이 없습니다.\")\n",
    "            break\n",
    "        \n",
    "        post = detail # 이하 호환을 위해 변수 이름 변경(및 복사)\n",
    "        checked_at = post[\"checked_at\"]\n",
    "\n",
    "        post_url = post[\"url\"]\n",
    "        REQUEST_REST = 1 + random.random()\n",
    "        \n",
    "        #response = requests.get(post_url, headers=headers, allow_redirects=False)\n",
    "        #isBanned = response.status_code != 200\n",
    "        while isBanned:\n",
    "            proxy = get_proxy_ip(\"clien\")\n",
    "            if proxy is None:\n",
    "                #isBanned = True\n",
    "                break\n",
    "            try:\n",
    "                response = requests.get(post_url, headers=headers, proxies=proxy, allow_redirects=False)\n",
    "            except requests.exceptions.ConnectTimeout as e:\n",
    "                print(f\"프록시 연결 시간 초과: {e}\")\n",
    "                return_proxy_ip(proxy[\"http\"],\"clien\",isBanned,isTimeout=True)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"알 수 없는 오류 발생: {e}\")\n",
    "                return_proxy_ip(proxy[\"http\"],\"clien\",True,isTimeout=False)\n",
    "                break\n",
    "            \n",
    "            isBanned = response.status_code != 200\n",
    "            return_proxy_ip(proxy[\"http\"],\"clien\",isBanned,isTimeout=False)\n",
    "        \n",
    "        if isBanned:\n",
    "            return_dict[\"status_code\"] = 403\n",
    "            return_dict[\"body\"] = \"[WARNING] DETAIL/clien IP 차단\"\n",
    "            update_status_banned(conn, table_name, post['url'])   \n",
    "            break\n",
    "\n",
    "        # update_status_unchanged(conn, table_name, post['url'])\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        comments_raw = soup.find_all(\"div\", class_=\"comment_row\")\n",
    "        all_comments = []\n",
    "\n",
    "        for row in comments_raw:\n",
    "                \n",
    "            if \"blocked\" in row.get(\"class\", []):\n",
    "                continue  # 차단된 댓글 제외\n",
    "\n",
    "            comment_content = row.find(\"div\", class_=\"comment_view\").get_text(separator=\"\\n\", strip=True)\n",
    "            comment_created_at = row.find(\"span\", class_=\"timestamp\").get_text(strip=True)\n",
    "            comment_created_at = re.search(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\", comment_created_at).group(0)\n",
    "            comment_created_at = datetime.strptime(comment_created_at, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            comment_like = row.find(\"div\", class_=\"comment_content_symph\")\n",
    "            comment_like = comment_like.find(\"strong\").text if comment_like else \"0\"\n",
    "\n",
    "            comment_data = {\n",
    "                \"created_at\": comment_created_at,\n",
    "                \"content\": comment_content,\n",
    "                \"like\": comment_like,\n",
    "                \"dislike\": None\n",
    "            }\n",
    "            all_comments.append(comment_data)\n",
    "\n",
    "        try: \n",
    "            hit = soup.find(\"div\", class_=\"post_author\").find(\"span\", class_=\"view_count\").find(\"strong\").text\n",
    "            hit = int(hit)\n",
    "        except: \n",
    "            hit = post[\"view\"]\n",
    "        \n",
    "        post_data = {\n",
    "            \"title\": soup.find(\"h3\", class_=\"post_subject\").find_all(\"span\")[0].text,\n",
    "            \"post_id\": post[\"post_id\"],\n",
    "            \"url\": post_url,\n",
    "            \"content\": soup.find(\"div\", class_=\"post_article\").get_text(separator=\"\\n\", strip=True),\n",
    "            \"view\": hit,\n",
    "            \"created_at\": post[\"created_at\"],\n",
    "            \"like\": int(soup.find(\"a\", class_=\"symph_count\").find(\"strong\").text if soup.find(\"a\", class_=\"symph_count\") else \"0\"),\n",
    "            \"dislike\": None,\n",
    "            \"comment_count\": int(soup.find(\"a\", class_=\"post_reply\").find(\"span\").text if soup.find(\"a\", class_=\"post_reply\") else \"0\"),\n",
    "            \"keywords\": post[\"keywords\"],\n",
    "            \"comment\": all_comments\n",
    "        }\n",
    "        \n",
    "        futures.append(analysis_executor.submit(analyze_post_with_gpt, post_data))\n",
    "        executing += 1\n",
    "        #time.sleep(REQUEST_REST)\n",
    "        \n",
    "        # if context.get_remaining_time_in_millis() < REMAINING_TIME_LIMIT:\n",
    "        #     break\n",
    "\n",
    "        # as_completed를 Request_rest만큼 대기\n",
    "        # 일단 gpt 처리된 것은 처리\n",
    "        try:\n",
    "            for future in as_completed(futures, timeout=REQUEST_REST if executing < EXECUTOR_MAX else None):\n",
    "                try:\n",
    "                    post_data = future.result()\n",
    "                    executing -= 1\n",
    "                    if post_data:\n",
    "                        all_post.append(post_data)\n",
    "                        update_changed_stats(conn, table_name, post_data['url'], post_data['comment_count'], post_data['view'], post_data['created_at'])\n",
    "                        print(f\"{post_data['url']} - Done!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing post: {e}\")\n",
    "        except TimeoutError:\n",
    "            print(\"gpt timeout! get next page...\")\n",
    "\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            post_data = future.result()\n",
    "            if post_data:\n",
    "                all_post.append(post_data)\n",
    "                update_changed_stats(conn, table_name, post_data['url'], post_data['comment_count'], post_data['view'], post_data['created_at'])\n",
    "                print(f\"{post_data['url']} - Done!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing post: {e}\")\n",
    "\n",
    "    if len(all_post) == 0:\n",
    "        return return_dict\n",
    "    save_res = save_s3_bucket_by_parquet(checked_at, platform='clien', data=all_post, id=lambda_id)\n",
    "    if save_res is None:\n",
    "        return {\n",
    "            \"status_code\": 500,\n",
    "            \"body\": \"[FATAL ERROR] DETAIL / S3 저장 실패\"\n",
    "        }\n",
    "    if return_dict[\"status_code\"] != 204:\n",
    "        return return_dict\n",
    "    else:\n",
    "        return {\n",
    "            \"status_code\": 200,\n",
    "            \"body\": \"[INFO] DETAIL / S3 저장 성공\"\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
