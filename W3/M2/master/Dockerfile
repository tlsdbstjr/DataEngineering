# Base Image
FROM ubuntu:20.04

# Set environment variables
ENV HADOOP_VERSION=3.3.6
ENV HADOOP_HOME=/usr/local/hadoop
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-arm64
ENV PATH=$JAVA_HOME/bin:$PATH

ENV HDFS_NAMENODE_USER=root
ENV HDFS_DATANODE_USER=root
ENV HDFS_SECONDARYNAMENODE_USER=root
ENV YARN_RESOURCEMANAGER_USER=root
ENV YARN_NODEMANAGER_USER=root


# Install necessary packages
RUN apt-get update && \
    apt-get install -y openjdk-8-jdk ssh rsync && \
    apt-get clean

# Copy the SSH private and public keys from host to container
# This assumes the keys are on the host at ~/.ssh/hadoop_id_rsa and ~/.ssh/hadoop_id_rsa.pub
COPY id_rsa /root/.ssh/id_rsa
COPY id_rsa.pub /root/.ssh/id_rsa.pub

# Setup SSH authorized_keys for password-less SSH access
RUN mkdir -p ~/.ssh && \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
    chmod 0600 ~/.ssh/authorized_keys && \
    chmod 0600 ~/.ssh/id_rsa && \
    chmod 0600 ~/.ssh/id_rsa.pub

# Download and install Hadoop
COPY hadoop-$HADOOP_VERSION.tar.gz /hadoop-$HADOOP_VERSION.tar.gz
RUN tar -xzf hadoop-$HADOOP_VERSION.tar.gz && \
    mv hadoop-$HADOOP_VERSION $HADOOP_HOME && \
    rm hadoop-$HADOOP_VERSION.tar.gz

# Configure Hadoop
COPY core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml
COPY mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml
COPY yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml
COPY workers $HADOOP_HOME/etc/hadoop/workers

# Configure SSH for Hadoop
#RUN ssh-keygen -t rsa -P "" -f ~/.ssh/dummy
#COPY id_rsa ~/.ssh/id_rsa
#COPY id_rsa.pub ~/.ssh/id_rsa.pub
#RUN cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
#    chmod 0600 ~/.ssh/authorized_keys

# Format the Hadoop namenode
# RUN $HADOOP_HOME/bin/hdfs namenode -format

# Expose Hadoop ports
EXPOSE 8088 9870 9864 9866 9867

RUN echo "export JAVA_HOME=$JAVA_HOME" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh

# Start Hadoop services
CMD service ssh start && \
    $HADOOP_HOME/bin/hdfs namenode -format && \
    $HADOOP_HOME/sbin/start-dfs.sh && \ 
    $HADOOP_HOME/sbin/start-yarn.sh && \
    bash

#ENTRYPOINT ["tail", "-f", "/dev/null"]